{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c909981-4596-403c-a202-1330d29ce300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "#from langchain_huggingface import HuggingFacePipeline\n",
    "# 1. 加载本地模型\n",
    "model_path = \"models/Qwen3-1.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", trust_remote_code=True)\n",
    "# 2. 创建文本生成pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=3000,\n",
    "    temperature=0.2,\n",
    "    do_sample=True\n",
    ")\n",
    "# 3. 转换为LangChain可用的LLM\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "template = \"\"\"<|im_start|>system\n",
    "你是一个法律AI助手，请根据提供的上下文信息回答问题。请直接回答问题，不要解释推理过程。<|im_end|>\n",
    "<|im_start|>user\n",
    "上下文：{context}\n",
    "\n",
    "问题：{question}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58654d6f-f741-4570-af10-cb4fc9c18438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "# 加载同一个 embedding 模型（必须和保存时一致）\n",
    "EMBED_PATH = \"models/BAAI--bge-small-zh-v1.5\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=EMBED_PATH)\n",
    "# 加载向量数据库，并允许危险的反序列化\n",
    "vectorstore = FAISS.load_local(\"faiss_lawdb\", embedding_model, allow_dangerous_deserialization=True)\n",
    "qa_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2535a-bf2f-4460-8c8b-14977c1102d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reference(docs: list) -> str:\n",
    "    references = []\n",
    "    for doc in docs:\n",
    "        meta = doc.metadata\n",
    "        law_type = meta.get(\"law_type\", \"未知法律\")\n",
    "        structure = meta.get(\"structure\", {})\n",
    "        bian = structure.get(\"编\", {}).get(\"序号\", \"\")\n",
    "        bian_title = structure.get(\"编\", {}).get(\"标题\", \"\")\n",
    "        zhang = structure.get(\"章\", {}).get(\"序号\", \"\")\n",
    "        zhang_title = structure.get(\"章\", {}).get(\"标题\", \"\")\n",
    "        jie = structure.get(\"节\", {}).get(\"序号\", \"\")\n",
    "        jie_title = structure.get(\"节\", {}).get(\"标题\", \"\")\n",
    "        # 拼接结构字符串\n",
    "        structure_str = f\"第{bian}编 {bian_title} 第{zhang}章 {zhang_title}\"\n",
    "        if jie:\n",
    "            structure_str += f\" 第{jie}节 {jie_title}\"\n",
    "        content = doc.page_content\n",
    "        reference = f\"《{law_type}》 {structure_str}\\n{content}\"\n",
    "        references.append(reference)\n",
    "\n",
    "    return \"\\n\\n\".join(references)  # 多条之间空两行分隔\n",
    "\n",
    "def extract_final_answer(response_text: str,docs) -> str:\n",
    "    # 提取 assistant 标签之后的内容（如果有）\n",
    "    if \"<|im_start|>assistant\" in response_text:\n",
    "        raw_an = response_text.split(\"<|im_start|>assistant\")[-1].strip()\n",
    "    else:\n",
    "        raw_an = response_text.strip()\n",
    "    # 提取被 <think> 包围的内容\n",
    "    import re\n",
    "    think_matches = re.findall(r\"<think>(.*?)</think>\", raw_an, re.DOTALL)\n",
    "    # 去除 <think> 标签及其内容，保留非 think 内容\n",
    "    raw_an_without_think = re.sub(r\"<think>.*?</think>\", \"\", raw_an, flags=re.DOTALL).strip()\n",
    "    reference = build_reference(docs)\n",
    "    # 拼接回答 + HTML 格式参考法条\n",
    "    answer = (\n",
    "        f\"{raw_an_without_think}<br><div class='reference-box'>参考条文：\\n{reference}</div>\"\n",
    "    )\n",
    "    return answer\n",
    "import gradio as gr\n",
    "custom_css = \"\"\"\n",
    ".reference-box {\n",
    "    background-color: #f0f4ff;  /* 淡蓝色背景 */\n",
    "    border-left: 4px solid #3b82f6;\n",
    "    padding: 8px;\n",
    "    margin-top: 6px;\n",
    "    border-radius: 4px;\n",
    "    font-size: 14px;\n",
    "    color: #333;\n",
    "}\n",
    "\"\"\"\n",
    "def gr_rag_chatbot(history, query):\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    response = qa_chain.invoke({\"context\": context, \"question\": query})\n",
    "    raw_answer = response['text']\n",
    "    answer = extract_final_answer(raw_answer,docs)\n",
    "    # 更新对话历史：右边用户，下面AI回答\n",
    "    history.append((f\"👤 {query}\", f\"🤖 {answer}\"))\n",
    "    return history, \"\"  # 返回对话内容 & 清空输入框\n",
    "with gr.Blocks(css=custom_css) as demo:\n",
    "    gr.Markdown(\"# 📚 法律助手 Demo\")\n",
    "    chatbot = gr.Chatbot(label=\"对话记录\", height=600)\n",
    "    with gr.Row():\n",
    "        msg_input = gr.Textbox(\n",
    "            placeholder=\"请输入你的法律问题，例如：婚姻无效的情形有哪些？\",\n",
    "            show_label=False,\n",
    "            lines=3,\n",
    "            scale=4\n",
    "        )\n",
    "        send_btn = gr.Button(\"发送\", scale=1)\n",
    "    state = gr.State([])  # 保存对话历史\n",
    "    send_btn.click(\n",
    "        fn=gr_rag_chatbot,\n",
    "        inputs=[state, msg_input],\n",
    "        outputs=[chatbot, msg_input]\n",
    "    )\n",
    "demo.launch(server_name=\"0.0.0.0\", server_port=7860)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
